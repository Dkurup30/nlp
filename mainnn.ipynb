{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "305992c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting anyio<5.0,>=3.0 (from gradio)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.8.0 (from gradio)\n",
      "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.30.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.16-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (24.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (10.3.0)\n",
      "Collecting pydantic<2.12,>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.11.6-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio-client==1.8.0->gradio) (2024.12.0)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.8.0->gradio)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (2.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Downloading httpcore-1.0.8-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
      "Requirement already satisfied: requests in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.33.1-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.2.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
      "   ---------------------------------------- 0.0/46.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.9/46.9 MB 16.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 6.8/46.9 MB 16.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 10.2/46.9 MB 17.2 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 14.9/46.9 MB 18.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 19.4/46.9 MB 18.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 23.6/46.9 MB 18.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 27.8/46.9 MB 18.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 31.7/46.9 MB 19.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 36.2/46.9 MB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 40.4/46.9 MB 19.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.5/46.9 MB 18.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.9/46.9 MB 18.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.9/46.9 MB 18.2 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.8-py3-none-any.whl (78 kB)\n",
      "Downloading orjson-3.10.16-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 18.0 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.11.6-py3-none-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 4.2/11.6 MB 20.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.1/11.6 MB 20.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 19.0 MB/s eta 0:00:00\n",
      "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Installing collected packages: pydub, websockets, typing-inspection, tomlkit, shellingham, semantic-version, ruff, python-multipart, pydantic-core, orjson, h11, groovy, ffmpy, anyio, annotated-types, aiofiles, uvicorn, starlette, pydantic, httpcore, typer, httpx, fastapi, safehttpx, gradio-client, gradio\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.9.0\n",
      "    Uninstalling h11-0.9.0:\n",
      "      Successfully uninstalled h11-0.9.0\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 0.9.1\n",
      "    Uninstalling httpcore-0.9.1:\n",
      "      Successfully uninstalled httpcore-0.9.1\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.13.3\n",
      "    Uninstalling httpx-0.13.3:\n",
      "      Successfully uninstalled httpx-0.13.3\n",
      "Successfully installed aiofiles-24.1.0 annotated-types-0.7.0 anyio-4.9.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 h11-0.14.0 httpcore-1.0.8 httpx-0.28.1 orjson-3.10.16 pydantic-2.11.3 pydantic-core-2.33.1 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.46.2 tomlkit-0.13.2 typer-0.15.2 typing-inspection-0.4.0 uvicorn-0.34.2 websockets-15.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow (c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "googletrans 4.0.0rc1 requires httpx==0.13.3, but you have httpx 0.28.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abad97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✅ Imports\n",
    "import gradio as gr\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ✅ Load environment variables\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENWEATHER_API_KEY\")\n",
    "\n",
    "# ✅ Load Crop Dataset and Train Model\n",
    "df = pd.read_csv(\"Crop_recommendation.csv\")\n",
    "\n",
    "# Features and labels\n",
    "X = df[[\"temperature\", \"humidity\"]]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ✅ NER Setup\n",
    "ner_model_name = \"Davlan/bert-base-multilingual-cased-ner-hrl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(ner_model_name)\n",
    "ner_model = AutoModelForTokenClassification.from_pretrained(ner_model_name)\n",
    "ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=tokenizer, grouped_entities=True)\n",
    "\n",
    "# ✅ WSD Model and Sense Inventory\n",
    "wsd_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sense_inventory = {\n",
    "    \"plant_1\": \"a living organism like a crop or tree\",\n",
    "    \"plant_2\": \"an industrial facility such as a pesticide plant\",\n",
    "    \"spray_1\": \"the act of spraying liquid on crops\",\n",
    "    \"spray_2\": \"a physical pesticide product in a bottle\"\n",
    "}\n",
    "\n",
    "def disambiguate_word(context_sentence, word, sense_inventory):\n",
    "    senses = [k for k in sense_inventory if k.startswith(word)]\n",
    "    if not senses:\n",
    "        return None\n",
    "\n",
    "    context_embedding = wsd_model.encode(context_sentence, convert_to_tensor=True)\n",
    "    best_sense, best_score = None, -1\n",
    "    for sense_key in senses:\n",
    "        gloss = sense_inventory[sense_key]\n",
    "        gloss_embedding = wsd_model.encode(gloss, convert_to_tensor=True)\n",
    "        score = util.pytorch_cos_sim(context_embedding, gloss_embedding).item()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_sense = sense_key\n",
    "    return best_sense\n",
    "\n",
    "# ✅ Extract location from query using NER\n",
    "def extract_location(text):\n",
    "    entities = ner_pipeline(text)\n",
    "    for ent in entities:\n",
    "        if ent[\"entity_group\"] == \"LOC\":\n",
    "            return ent[\"word\"]\n",
    "    return None\n",
    "\n",
    "# ✅ Get Weather Info\n",
    "# def get_weather_data(location, api_key):\n",
    "#     try:\n",
    "#         url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={api_key}&units=metric\"\n",
    "#         response = requests.get(url)\n",
    "#         data = response.json()\n",
    "#         if data.get(\"cod\") != 200:\n",
    "#             return None, None\n",
    "#         weather_desc = data['weather'][0]['description']\n",
    "#         temperature = data['main']['temp']\n",
    "#         humidity = data['main']['humidity']\n",
    "#         return weather_desc, temperature , humidity\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching weather: {e}\")\n",
    "#         return None, None\n",
    "\n",
    "# # ✅ Predict crop using only city\n",
    "# def predict_crop_from_city(city):\n",
    "#     weather_desc, temp , humidity = get_weather_data(city, API_KEY)\n",
    "    \n",
    "#     if temp is None:\n",
    "#         return f\"❌ Couldn't fetch weather info for '{city}'. Please try another location.\"\n",
    "\n",
    "\n",
    "#     # Default values from dataset or assumption\n",
    "#     # avg_N = 90\n",
    "#     # avg_P = 42\n",
    "#     # avg_K = 43\n",
    "#     # avg_ph = 6.5\n",
    "#     # avg_rainfall = 100\n",
    "\n",
    "#     #input_data = [[avg_N, avg_P, avg_K, temp, humidity, avg_ph, avg_rainfall]]\n",
    "#     input_data = [[ temp, humidity]]\n",
    "#     crop_encoded = model.predict(input_data)[0]\n",
    "#     crop_label = label_encoder.inverse_transform([crop_encoded])[0]\n",
    "\n",
    "#     return f\"🌤️ Weather in {city}: {weather_desc}, {temp}°C\\n🌱 Recommended crop: {crop_label}\"\n",
    "\n",
    "\n",
    "# def recommend_crop(city):\n",
    "#     weather_desc, temp , humidity = get_weather_data(city, API_KEY)\n",
    "\n",
    "    \n",
    "#     # Predict crop\n",
    "#     input_data = np.array([[temp, humidity]])\n",
    "#     crop_encoded = model.predict(input_data)[0]\n",
    "#     crop_label = label_encoder.inverse_transform([crop_encoded])[0]\n",
    "\n",
    "#     return f\"  Weather Description: {weather_desc}\\n 🌡 Temperature: {temp}°C\\n💧 Humidity: {humidity}%\\n🌱 Recommended crop: {crop_label} \"\n",
    "\n",
    "# # --------------------------------\n",
    "# # ✅ Gradio UI\n",
    "# demo = gr.Interface(\n",
    "#     fn=recommend_crop,\n",
    "#     inputs=gr.Textbox(label=\"Enter your city\"),\n",
    "#     outputs=\"text\",\n",
    "#     title=\"🌾 Crop Recommendation Bot\",\n",
    "#     description=\"Enter your city name to get real-time crop suggestions based on weather data.\"\n",
    "# )\n",
    "\n",
    "# demo.launch()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
