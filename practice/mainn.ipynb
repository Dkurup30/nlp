{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ae3bc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dotenv) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow (c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e68fd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9931818181818182\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Crop_recommendation.csv\")\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Optional: Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82cfa7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather in Chennai: scattered clouds\n",
      "Temperature: 30.47Â°C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ± Recommended crop for Chennai is: coffee\n",
      "User: What plant should I grow in summer in {city}?\n",
      "Bot: Please include your location in the query.\n",
      "\n",
      "User: Is there a pesticide plant near my village?\n",
      "Bot: Did you mean a factory? For crop suggestions, please clarify.\n",
      "Couldn't fetch weather info for .\n"
     ]
    }
   ],
   "source": [
    "# âœ… Imports\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "from langdetect import detect\n",
    "\n",
    "# âœ… Load environment variables\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENWEATHER_API_KEY\")\n",
    "# âœ… NER Setup\n",
    "ner_model_name = \"Davlan/bert-base-multilingual-cased-ner-hrl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(ner_model_name)\n",
    "ner_model = AutoModelForTokenClassification.from_pretrained(ner_model_name)\n",
    "ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=tokenizer, grouped_entities=True)\n",
    "\n",
    "# âœ… WSD Model and Sense Inventory\n",
    "wsd_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sense_inventory = {\n",
    "    \"plant_1\": \"a living organism like a crop or tree\",\n",
    "    \"plant_2\": \"an industrial facility such as a pesticide plant\",\n",
    "    \"spray_1\": \"the act of spraying liquid on crops\",\n",
    "    \"spray_2\": \"a physical pesticide product in a bottle\"\n",
    "}\n",
    "\n",
    "def disambiguate_word(context_sentence, word, sense_inventory):\n",
    "    senses = [k for k in sense_inventory if k.startswith(word)]\n",
    "    if not senses:\n",
    "        return None\n",
    "\n",
    "    context_embedding = wsd_model.encode(context_sentence, convert_to_tensor=True)\n",
    "    best_sense, best_score = None, -1\n",
    "    for sense_key in senses:\n",
    "        gloss = sense_inventory[sense_key]\n",
    "        gloss_embedding = wsd_model.encode(gloss, convert_to_tensor=True)\n",
    "        score = util.pytorch_cos_sim(context_embedding, gloss_embedding).item()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_sense = sense_key\n",
    "    return best_sense\n",
    "\n",
    "# âœ… Extract location from query\n",
    "def extract_location(text):\n",
    "    entities = ner_pipeline(text)\n",
    "    for ent in entities:\n",
    "        if ent[\"entity_group\"] == \"LOC\":\n",
    "            return ent[\"word\"]\n",
    "    return None\n",
    "\n",
    "# âœ… Weather + Crop Suggestion Logic\n",
    "# def get_weather_desc(location, api_key):\n",
    "#    try:\n",
    "#         url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={API_KEY}&units=metric\"\n",
    "#         response = requests.get(url)\n",
    "#         #print(\"API Response:\", response.json())  # Debugging print\n",
    "#         data = response.json()\n",
    "#         if data.get(\"cod\") != 200:\n",
    "#             return None\n",
    "#         return data['weather'][0]['description']\n",
    "#    except Exception as e:\n",
    "#         print(f\"Error: {e}\")  # Print error if any\n",
    "#         return None\n",
    "\n",
    "def get_weather_data(location, api_key):\n",
    "    try:\n",
    "        # Construct the API URL\n",
    "        url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={api_key}&units=metric\"  # 'metric' for Celsius\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        \n",
    "        if data.get(\"cod\") != 200:\n",
    "            return None, None  # Return None if API call is unsuccessful\n",
    "        \n",
    "        # Extract weather description and temperature\n",
    "        weather_desc = data['weather'][0]['description']\n",
    "        temperature = data['main']['temp']  # Temperature in Celsius\n",
    "        \n",
    "        return weather_desc, temperature\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# def suggest_crops(weather_desc, month, soil_type=\"loamy\"):\n",
    "#     crop_db = {\n",
    "#         \"loamy\": {\n",
    "#             \"summer\": [\"maize\", \"cotton\", \"groundnut\"],\n",
    "#             \"monsoon\": [\"rice\", \"millets\", \"soybean\"],\n",
    "#             \"winter\": [\"wheat\", \"mustard\", \"gram\"]\n",
    "#         },\n",
    "#         \"clay\": {\n",
    "#             \"summer\": [\"sugarcane\"],\n",
    "#             \"monsoon\": [\"paddy\", \"jute\"],\n",
    "#             \"winter\": [\"barley\", \"wheat\"]\n",
    "#         }\n",
    "#     }\n",
    "#     if \"rain\" in weather_desc:\n",
    "#         season = \"monsoon\"\n",
    "#     elif month in [\"March\", \"April\", \"May\", \"June\"]:\n",
    "#         season = \"summer\"\n",
    "#     else:\n",
    "#         season = \"winter\"\n",
    "#     return crop_db.get(soil_type, {}).get(season, [\"No crop data available\"])\n",
    "\n",
    "# âœ… Main Chatbot Function\n",
    "def get_crop_recommendation(query):\n",
    "    ambiguous_words = [\"plant\", \"spray\"]\n",
    "    disambigs = {}\n",
    "    for word in ambiguous_words:\n",
    "        if word in query.lower():\n",
    "            sense = disambiguate_word(query, word, sense_inventory)\n",
    "            if sense:\n",
    "                disambigs[word] = sense\n",
    "\n",
    "    # Handle wrong sense\n",
    "    if \"plant\" in disambigs and disambigs[\"plant\"] == \"plant_2\":\n",
    "        return \"Did you mean a factory? For crop suggestions, please clarify.\"\n",
    "\n",
    "    location = extract_location(query)\n",
    "    if not location:\n",
    "        return \"Please include your location in the query.\"\n",
    "\n",
    "    # Get weather data (description and temperature)\n",
    "    weather_desc, temperature = get_weather_data(location, API_KEY)\n",
    "    \n",
    "    if not weather_desc:\n",
    "        return f\"Couldn't get weather info for {location}.\"\n",
    "\n",
    "    # Use only the weather description for crop suggestion\n",
    "    current_month = datetime.now().strftime(\"%B\")\n",
    "    crops = predict_crop(location)\n",
    "    \n",
    "    return f\"ðŸŒ¾ Based on {weather_desc} in {location}, recommended crops are: {', '.join(crops)}\"\n",
    "\n",
    "location = \"Chennai\"  # You can change this to your preferred location\n",
    "weather_desc, temperature = get_weather_data(location, API_KEY)\n",
    "\n",
    "if weather_desc and temperature:\n",
    "    print(f\"Weather in {location}: {weather_desc}\")\n",
    "    print(f\"Temperature: {temperature}Â°C\")\n",
    "else:\n",
    "    print(f\"Couldn't get weather info for {location}.\")\n",
    "\n",
    "def predict_crop(city):\n",
    "    weather_desc,temp = get_weather_data(city, API_KEY)\n",
    "    if temp is None:\n",
    "        return f\"Couldn't fetch weather info for {city}.\"\n",
    "\n",
    "    # Collect other inputs from the user\n",
    "    # N = float(input(\"Enter Nitrogen (N) value: \"))\n",
    "    # P = float(input(\"Enter Phosphorus (P) value: \"))\n",
    "    # K = float(input(\"Enter Potassium (K) value: \"))\n",
    "    # ph = float(input(\"Enter soil pH value: \"))\n",
    "    # rainfall = float(input(\"Enter expected rainfall (mm): \"))\n",
    "\n",
    "    # Create input array\n",
    "    #input_data = [[N, P, K, temp, humidity, ph, rainfall]]\n",
    "    avg_N = 90\n",
    "    avg_P = 42\n",
    "    avg_K = 43\n",
    "    avg_ph = 6.5\n",
    "    avg_rainfall = 100\n",
    "    humidity = 68\n",
    "\n",
    "    # Create input with only city-based temp/humidity + defaults\n",
    "    input_data = [[avg_N, avg_P, avg_K, temp, humidity, avg_ph, avg_rainfall]]\n",
    "    #input_data = [[ temp]]\n",
    "\n",
    "    # Predict crop\n",
    "    crop_encoded = model.predict(input_data)[0]\n",
    "    crop_label = label_encoder.inverse_transform([crop_encoded])[0]\n",
    "\n",
    "    return f\"ðŸŒ± Recommended crop for {city} is: {crop_label}\"\n",
    "\n",
    "city = input(\"Enter your city: \")\n",
    "print(predict_crop(city))\n",
    "# ðŸ§ª Example\n",
    "query1 = \"What plant should I grow in summer in {city}?\"\n",
    "query2 = \"Is there a pesticide plant near my village?\"\n",
    "print(\"User:\", query1)\n",
    "print(\"Bot:\", get_crop_recommendation(query1))\n",
    "print(\"\\nUser:\", query2)\n",
    "print(\"Bot:\", get_crop_recommendation(query2))\n",
    "\n",
    "city = input(\"Enter your city: \")\n",
    "print(predict_crop(city))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
