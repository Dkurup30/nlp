{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12467c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deep-translator in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from deep-translator) (4.13.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from deep-translator) (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kurup\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow (c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2301fe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n",
      "c:\\Users\\kurup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‚úÖ Imports\n",
    "import gradio as gr\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from deep_translator import GoogleTranslator # Replacing googletrans\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ‚úÖ Load environment variables\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENWEATHER_API_KEY\")\n",
    "\n",
    "# ‚úÖ Load Crop Dataset and Train Model\n",
    "df = pd.read_csv(\"Crop_recommendation.csv\")\n",
    "X = df[[\"temperature\", \"humidity\"]]\n",
    "y = df[\"label\"]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ‚úÖ Setup Translator\n",
    "# lang = single_detection('bonjour la vie', api_key='your_api_key')\n",
    "translator = GoogleTranslator(source='auto', target='en')\n",
    "# Default source is auto-detect, target is English\n",
    "\n",
    "# ‚úÖ NER Setup\n",
    "ner_model_name = \"Davlan/bert-base-multilingual-cased-ner-hrl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(ner_model_name)\n",
    "ner_model = AutoModelForTokenClassification.from_pretrained(ner_model_name)\n",
    "ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=tokenizer, grouped_entities=True)\n",
    "\n",
    "# ‚úÖ WSD Setup\n",
    "wsd_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sense_inventory = {\n",
    "    \"plant_1\": \"a living organism like a crop or tree\",\n",
    "    \"plant_2\": \"an industrial facility such as a pesticide plant\",\n",
    "    \"spray_1\": \"the act of spraying liquid on crops\",\n",
    "    \"spray_2\": \"a physical pesticide product in a bottle\"\n",
    "}\n",
    "\n",
    "def disambiguate_word(context_sentence, word, sense_inventory):\n",
    "    senses = [k for k in sense_inventory if k.startswith(word)]\n",
    "    if not senses:\n",
    "        return None\n",
    "    context_embedding = wsd_model.encode(context_sentence, convert_to_tensor=True)\n",
    "    best_sense, best_score = None, -1\n",
    "    for sense_key in senses:\n",
    "        gloss = sense_inventory[sense_key]\n",
    "        gloss_embedding = wsd_model.encode(gloss, convert_to_tensor=True)\n",
    "        score = util.pytorch_cos_sim(context_embedding, gloss_embedding).item()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_sense = sense_key\n",
    "    return best_sense\n",
    "\n",
    "# ‚úÖ Extract city\n",
    "def extract_location(text):\n",
    "    entities = ner_pipeline(text)\n",
    "    for ent in entities:\n",
    "        if ent[\"entity_group\"] == \"LOC\":\n",
    "            return ent[\"word\"]\n",
    "    return None\n",
    "\n",
    "# ‚úÖ Weather Fetching\n",
    "def get_weather_data(location, api_key):\n",
    "    try:\n",
    "        url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={api_key}&units=metric\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        if data.get(\"cod\") != 200:\n",
    "            return None, None, None\n",
    "        weather_desc = data['weather'][0]['description']\n",
    "        temperature = data['main']['temp']\n",
    "        humidity = data['main']['humidity']\n",
    "        return weather_desc, temperature, humidity\n",
    "    except Exception as e:\n",
    "        print(f\"Weather API error: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# ‚úÖ Main Bot Logic\n",
    "def query_bot(user_query):\n",
    "\n",
    "    # lang = single_detection(user_query, api_key='d5c60fec2be48ef146e29fb217a8933c')\n",
    "    # translator = GoogleTranslator(source='auto', target=lang)\n",
    "    # üîÅ Detect language and translate to English\n",
    "    translated_query = translator.translate(user_query)  # Automatically detects language\n",
    "    \n",
    "    # üîç WSD\n",
    "    ambiguous_words = [\"plant\", \"spray\"]\n",
    "    for word in ambiguous_words:\n",
    "        if word in translated_query.lower():\n",
    "            sense = disambiguate_word(translated_query, word, sense_inventory)\n",
    "            if sense and sense.endswith(\"2\"):  # pesticide factory or spray product\n",
    "                response = \"Did you mean a factory or a product? For crops, please clarify.\"\n",
    "                return translator.translate(response)  # Translate back to original language\n",
    "\n",
    "    # üèô Detect city\n",
    "    city = extract_location(translated_query)\n",
    "    if not city:\n",
    "        return translator.translate(\"Please mention your city in the question.\")\n",
    "\n",
    "    # üå¶ Get weather\n",
    "    weather_desc, temp, humidity = get_weather_data(city, API_KEY)\n",
    "    if temp is None:\n",
    "        return translator.translate(f\"Couldn't fetch weather info for {city}.\")\n",
    "\n",
    "    # üß† Decide: weather or crop\n",
    "    if \"weather\" in translated_query.lower() or \"temperature\" in translated_query.lower():\n",
    "        response = f\"üå¶ Weather in {city}: {weather_desc}, Temperature: {temp}¬∞C, Humidity: {humidity}%\"\n",
    "    else:\n",
    "        input_data = np.array([[temp, humidity]])\n",
    "        crop_encoded = model.predict(input_data)[0]\n",
    "        crop_label = label_encoder.inverse_transform([crop_encoded])[0]\n",
    "        response = f\" Weather in {city}: {weather_desc}\\n, {temp}¬∞C\\n Recommended crop: {crop_label}\"\n",
    "\n",
    "    # üîÅ Translate response back to user's language\n",
    "    return translator.translate(response)\n",
    "\n",
    "# ‚úÖ Gradio UI\n",
    "gr.Interface(\n",
    "    fn=query_bot,\n",
    "    inputs=gr.Textbox(label=\"Ask your query (in any language)\"),\n",
    "    outputs=gr.Textbox(label=\"Response\"),\n",
    "    title=\"üåæ Multilingual Crop & Weather Bot\",\n",
    "    description=\"Ask about crops or weather in your city, in any language!\"\n",
    ").launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
